{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mspawn /home/yanggl/anaconda3/bin/conda ENOENT. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from BNN import *\n",
    "from spikingjelly.activation_based import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/yanggl/code', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/home/yanggl/code', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#cifar10\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='/home/yanggl/code', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='/home/yanggl/code', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = BinaryConv2d(3, 6, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.conv2 = BinaryConv2d(6, 12, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.conv3 = BinaryConv2d(12, 24, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.sn3 = BinaryActivation()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = BinaryLinear(24*6*6, 10, bias=False)\n",
    "    def forward(self, x):\n",
    "        #大于127的变成1，小于等于127的变成0\n",
    "        x = torch.where(x>0.5, torch.tensor(1.), torch.tensor(-1.))\n",
    "        x = self.conv1(x)\n",
    "        #x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        # x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        x = self.sn1(x)\n",
    "        #print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.relu2(x)\n",
    "        #print(x.int())\n",
    "        x = self.pool2(x) \n",
    "        x = self.sn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.sn3(x)\n",
    "        #print(x.shape)\n",
    "        # x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.pool3(x)\n",
    "        #x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.int())\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanggl/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.426\n",
      "[1,   101] loss: 2.051\n",
      "[1,   201] loss: 1.642\n",
      "[1,   301] loss: 1.808\n",
      "[1,   401] loss: 1.812\n",
      "[1,   501] loss: 1.905\n",
      "[1,   601] loss: 1.934\n",
      "[1,   701] loss: 1.902\n",
      "[1,   801] loss: 2.138\n",
      "[1,   901] loss: 2.388\n",
      "[1,  1001] loss: 2.206\n",
      "[1,  1101] loss: 1.820\n",
      "[1,  1201] loss: 2.142\n",
      "[1,  1301] loss: 2.430\n",
      "[1,  1401] loss: 1.569\n",
      "[1,  1501] loss: 1.575\n",
      "[1,  1601] loss: 2.034\n",
      "[1,  1701] loss: 1.620\n",
      "[1,  1801] loss: 1.918\n",
      "[1,  1901] loss: 2.428\n",
      "[1,  2001] loss: 2.139\n",
      "[1,  2101] loss: 1.948\n",
      "[1,  2201] loss: 2.781\n",
      "[1,  2301] loss: 1.509\n",
      "[1,  2401] loss: 2.486\n",
      "[1,  2501] loss: 2.000\n",
      "[1,  2601] loss: 2.128\n",
      "[1,  2701] loss: 2.675\n",
      "[1,  2801] loss: 2.038\n",
      "[1,  2901] loss: 2.122\n",
      "[1,  3001] loss: 2.032\n",
      "[1,  3101] loss: 1.844\n",
      "Accuracy of the network on the 10000 test images: 29 %\n",
      "[2,     1] loss: 1.893\n",
      "[2,   101] loss: 1.956\n",
      "[2,   201] loss: 1.886\n",
      "[2,   301] loss: 1.768\n",
      "[2,   401] loss: 2.197\n",
      "[2,   501] loss: 2.073\n",
      "[2,   601] loss: 1.836\n",
      "[2,   701] loss: 1.553\n",
      "[2,   801] loss: 2.026\n",
      "[2,   901] loss: 1.926\n",
      "[2,  1001] loss: 1.524\n",
      "[2,  1101] loss: 2.319\n",
      "[2,  1201] loss: 1.753\n",
      "[2,  1301] loss: 1.671\n",
      "[2,  1401] loss: 1.523\n",
      "[2,  1501] loss: 1.957\n",
      "[2,  1601] loss: 2.200\n",
      "[2,  1701] loss: 2.001\n",
      "[2,  1801] loss: 2.326\n",
      "[2,  1901] loss: 2.109\n",
      "[2,  2001] loss: 2.128\n",
      "[2,  2101] loss: 1.903\n",
      "[2,  2201] loss: 2.222\n",
      "[2,  2301] loss: 2.469\n",
      "[2,  2401] loss: 1.925\n",
      "[2,  2501] loss: 1.913\n",
      "[2,  2601] loss: 2.483\n",
      "[2,  2701] loss: 1.921\n",
      "[2,  2801] loss: 2.124\n",
      "[2,  2901] loss: 1.944\n",
      "[2,  3001] loss: 1.906\n",
      "[2,  3101] loss: 2.341\n",
      "Accuracy of the network on the 10000 test images: 29 %\n",
      "[3,     1] loss: 2.459\n",
      "[3,   101] loss: 1.846\n",
      "[3,   201] loss: 2.354\n",
      "[3,   301] loss: 1.892\n",
      "[3,   401] loss: 1.951\n",
      "[3,   501] loss: 2.436\n",
      "[3,   601] loss: 1.773\n",
      "[3,   701] loss: 2.050\n",
      "[3,   801] loss: 1.955\n",
      "[3,   901] loss: 2.559\n",
      "[3,  1001] loss: 2.576\n",
      "[3,  1101] loss: 2.166\n",
      "[3,  1201] loss: 2.547\n",
      "[3,  1301] loss: 1.863\n",
      "[3,  1401] loss: 1.723\n",
      "[3,  1501] loss: 1.889\n",
      "[3,  1601] loss: 2.242\n",
      "[3,  1701] loss: 1.715\n",
      "[3,  1801] loss: 1.727\n",
      "[3,  1901] loss: 2.497\n",
      "[3,  2001] loss: 1.826\n",
      "[3,  2101] loss: 1.835\n",
      "[3,  2201] loss: 1.863\n",
      "[3,  2301] loss: 2.109\n",
      "[3,  2401] loss: 2.415\n",
      "[3,  2501] loss: 2.151\n",
      "[3,  2601] loss: 2.911\n",
      "[3,  2701] loss: 2.185\n",
      "[3,  2801] loss: 2.347\n",
      "[3,  2901] loss: 1.781\n",
      "[3,  3001] loss: 1.903\n",
      "[3,  3101] loss: 1.784\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[4,     1] loss: 2.403\n",
      "[4,   101] loss: 1.909\n",
      "[4,   201] loss: 1.683\n",
      "[4,   301] loss: 2.514\n",
      "[4,   401] loss: 2.429\n",
      "[4,   501] loss: 1.811\n",
      "[4,   601] loss: 2.309\n",
      "[4,   701] loss: 2.472\n",
      "[4,   801] loss: 2.273\n",
      "[4,   901] loss: 2.386\n",
      "[4,  1001] loss: 2.459\n",
      "[4,  1101] loss: 2.021\n",
      "[4,  1201] loss: 2.418\n",
      "[4,  1301] loss: 2.187\n",
      "[4,  1401] loss: 1.486\n",
      "[4,  1501] loss: 1.790\n",
      "[4,  1601] loss: 1.910\n",
      "[4,  1701] loss: 3.227\n",
      "[4,  1801] loss: 2.294\n",
      "[4,  1901] loss: 2.257\n",
      "[4,  2001] loss: 2.505\n",
      "[4,  2101] loss: 2.563\n",
      "[4,  2201] loss: 1.479\n",
      "[4,  2301] loss: 2.550\n",
      "[4,  2401] loss: 2.613\n",
      "[4,  2501] loss: 2.103\n",
      "[4,  2601] loss: 1.843\n",
      "[4,  2701] loss: 1.875\n",
      "[4,  2801] loss: 1.585\n",
      "[4,  2901] loss: 2.782\n",
      "[4,  3001] loss: 1.732\n",
      "[4,  3101] loss: 1.656\n",
      "Accuracy of the network on the 10000 test images: 26 %\n",
      "[5,     1] loss: 2.196\n",
      "[5,   101] loss: 1.641\n",
      "[5,   201] loss: 1.687\n",
      "[5,   301] loss: 2.340\n",
      "[5,   401] loss: 2.383\n",
      "[5,   501] loss: 2.485\n",
      "[5,   601] loss: 2.506\n",
      "[5,   701] loss: 2.707\n",
      "[5,   801] loss: 1.672\n",
      "[5,   901] loss: 2.313\n",
      "[5,  1001] loss: 2.479\n",
      "[5,  1101] loss: 2.324\n",
      "[5,  1201] loss: 1.917\n",
      "[5,  1301] loss: 3.209\n",
      "[5,  1401] loss: 1.817\n",
      "[5,  1501] loss: 1.544\n",
      "[5,  1601] loss: 2.190\n",
      "[5,  1701] loss: 2.191\n",
      "[5,  1801] loss: 1.804\n",
      "[5,  1901] loss: 1.929\n",
      "[5,  2001] loss: 2.408\n",
      "[5,  2101] loss: 2.331\n",
      "[5,  2201] loss: 2.086\n",
      "[5,  2301] loss: 2.077\n",
      "[5,  2401] loss: 2.624\n",
      "[5,  2501] loss: 2.692\n",
      "[5,  2601] loss: 2.032\n",
      "[5,  2701] loss: 2.137\n",
      "[5,  2801] loss: 2.320\n",
      "[5,  2901] loss: 1.683\n",
      "[5,  3001] loss: 1.875\n",
      "[5,  3101] loss: 3.038\n",
      "Accuracy of the network on the 10000 test images: 28 %\n",
      "[6,     1] loss: 2.041\n",
      "[6,   101] loss: 2.366\n",
      "[6,   201] loss: 2.586\n",
      "[6,   301] loss: 2.318\n",
      "[6,   401] loss: 2.742\n",
      "[6,   501] loss: 2.079\n",
      "[6,   601] loss: 2.769\n",
      "[6,   701] loss: 1.933\n",
      "[6,   801] loss: 2.443\n",
      "[6,   901] loss: 2.134\n",
      "[6,  1001] loss: 1.924\n",
      "[6,  1101] loss: 1.928\n",
      "[6,  1201] loss: 2.506\n",
      "[6,  1301] loss: 2.372\n",
      "[6,  1401] loss: 2.074\n",
      "[6,  1501] loss: 2.511\n",
      "[6,  1601] loss: 2.146\n",
      "[6,  1701] loss: 3.684\n",
      "[6,  1801] loss: 1.972\n",
      "[6,  1901] loss: 2.199\n",
      "[6,  2001] loss: 2.792\n",
      "[6,  2101] loss: 2.386\n",
      "[6,  2201] loss: 2.172\n",
      "[6,  2301] loss: 2.426\n",
      "[6,  2401] loss: 2.001\n",
      "[6,  2501] loss: 2.275\n",
      "[6,  2601] loss: 2.718\n",
      "[6,  2701] loss: 2.246\n",
      "[6,  2801] loss: 2.913\n",
      "[6,  2901] loss: 2.496\n",
      "[6,  3001] loss: 2.077\n",
      "[6,  3101] loss: 2.705\n",
      "Accuracy of the network on the 10000 test images: 26 %\n",
      "[7,     1] loss: 2.249\n",
      "[7,   101] loss: 2.426\n",
      "[7,   201] loss: 2.699\n",
      "[7,   301] loss: 2.159\n",
      "[7,   401] loss: 2.036\n",
      "[7,   501] loss: 1.920\n",
      "[7,   601] loss: 2.260\n",
      "[7,   701] loss: 1.792\n",
      "[7,   801] loss: 2.284\n",
      "[7,   901] loss: 2.859\n",
      "[7,  1001] loss: 1.953\n",
      "[7,  1101] loss: 2.883\n",
      "[7,  1201] loss: 2.402\n",
      "[7,  1301] loss: 2.529\n",
      "[7,  1401] loss: 2.663\n",
      "[7,  1501] loss: 2.277\n",
      "[7,  1601] loss: 2.419\n",
      "[7,  1701] loss: 1.869\n",
      "[7,  1801] loss: 2.287\n",
      "[7,  1901] loss: 2.588\n",
      "[7,  2001] loss: 2.314\n",
      "[7,  2101] loss: 2.435\n",
      "[7,  2201] loss: 2.727\n",
      "[7,  2301] loss: 1.765\n",
      "[7,  2401] loss: 2.319\n",
      "[7,  2501] loss: 2.968\n",
      "[7,  2601] loss: 2.556\n",
      "[7,  2701] loss: 2.483\n",
      "[7,  2801] loss: 1.600\n",
      "[7,  2901] loss: 2.570\n",
      "[7,  3001] loss: 1.569\n",
      "[7,  3101] loss: 1.356\n",
      "Accuracy of the network on the 10000 test images: 26 %\n",
      "[8,     1] loss: 2.024\n",
      "[8,   101] loss: 3.205\n",
      "[8,   201] loss: 2.459\n",
      "[8,   301] loss: 1.848\n",
      "[8,   401] loss: 2.026\n",
      "[8,   501] loss: 2.810\n",
      "[8,   601] loss: 1.907\n",
      "[8,   701] loss: 2.478\n",
      "[8,   801] loss: 2.569\n",
      "[8,   901] loss: 2.358\n",
      "[8,  1001] loss: 2.657\n",
      "[8,  1101] loss: 2.561\n",
      "[8,  1201] loss: 2.420\n",
      "[8,  1301] loss: 2.467\n",
      "[8,  1401] loss: 2.699\n",
      "[8,  1501] loss: 2.090\n",
      "[8,  1601] loss: 2.837\n",
      "[8,  1701] loss: 2.152\n",
      "[8,  1801] loss: 2.166\n",
      "[8,  1901] loss: 2.443\n",
      "[8,  2001] loss: 2.598\n",
      "[8,  2101] loss: 2.261\n",
      "[8,  2201] loss: 2.795\n",
      "[8,  2301] loss: 2.579\n",
      "[8,  2401] loss: 2.724\n",
      "[8,  2501] loss: 1.801\n",
      "[8,  2601] loss: 2.824\n",
      "[8,  2701] loss: 2.145\n",
      "[8,  2801] loss: 2.993\n",
      "[8,  2901] loss: 2.541\n",
      "[8,  3001] loss: 2.140\n",
      "[8,  3101] loss: 1.641\n",
      "Accuracy of the network on the 10000 test images: 21 %\n",
      "[9,     1] loss: 2.842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     20\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mLeNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#大于127的变成1，小于等于127的变成0\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#x = self.pool1(x)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#print(x.int())\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#x = self.pool1(x)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#print(x.int())\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "net = LeNet()\n",
    "from tqdm import tqdm\n",
    "np.int = int\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LR = 0.001\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "EPOCH = 10\n",
    "device = torch.device('cuda:0')\n",
    "net.to(device)\n",
    "for epoch in range(EPOCH):\n",
    "    net.train()\n",
    "    for i ,data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device).cuda()\n",
    "        labels = labels.to(device).cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        functional.reset_net(net)\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.item()))\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "torch.save(net.state_dict(), 'weight/lenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_Bconvd(BinaryConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(scale_Bconvd, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "    def forward(self, x):\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        scaling_factor = torch.mean(torch.mean(torch.mean(torch.mean(abs(w),dim=3,keepdim=True),dim=2,keepdim=True),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        #print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "    \n",
    "        return F.conv2d(x, bw, self.bias, self.stride,\n",
    "                    self.padding, self.dilation, self.groups)\n",
    "class scale_Blinear(BinaryLinear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super(scale_Blinear, self).__init__(in_features, out_features, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        # print(w.shape)\n",
    "        scaling_factor = torch.mean(torch.mean(abs(w),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        #print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "        \n",
    "        return F.linear(x, bw, self.bias)\n",
    "    \n",
    "class scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 3, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()\n",
    "        self.conv2 = scale_Bconvd(3, 6, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.fc1 = scale_Blinear(6*12*12, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = scale_Blinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = scale_Blinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = torch.where(x>0.5, torch.tensor(1.), torch.tensor(-1.))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        x = self.sn1(x)\n",
    "        #print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.relu2(x)\n",
    "        #print(x.int())\n",
    "        x = self.pool2(x)\n",
    "        x = self.sn2(x)\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.pool3(x)\n",
    "        #x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.int())\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 91 %\n"
     ]
    }
   ],
   "source": [
    "#将权重加载，二值化，保存为另外一个pth文件\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "net = LeNet()\n",
    "device = torch.device('cuda:0')\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load('weight/lenet.pth',weights_only=True))\n",
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        param.data = BinaryWeight.apply(param.data)\n",
    "torch.save(net.state_dict(), 'weight/lenet_binary.pth')\n",
    "#加载二值化后的权重\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.,  1.,  ..., -1., -1.,  1.],\n",
      "        [ 1., -1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [-1.,  1., -1.,  ...,  1.,  1., -1.],\n",
      "        ...,\n",
      "        [ 1., -1.,  1.,  ..., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1., -1., -1.],\n",
      "        [ 1., -1.,  1.,  ..., -1.,  1.,  1.]], device='cuda:0')\n",
      "torch.Size([10, 864])\n",
      "torch.Size([8640])\n",
      "tensor([ 1, -1,  1,  ..., -1,  1,  1], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#将网络第一层的权重导出\n",
    "conv1_weight = net.conv1.weight.data\n",
    "#print(conv1_weight)\n",
    "conv1_weight = conv1_weight.view(-1)\n",
    "#print(conv1_weight.shape)\n",
    "conv1_weight_int = conv1_weight.int()\n",
    "#print(conv1_weight_int)\n",
    "#将第一层的权重导出为txt文件\n",
    "with open('test_array/test_conv1_weight_txt.txt', 'w') as f:\n",
    "    for weight in conv1_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "#将网络第二层的权重导出\n",
    "conv2_weight = net.conv2.weight.data\n",
    "#print(conv2_weight.shape)\n",
    "#print(conv2_weight)\n",
    "conv2_weight = conv2_weight.view(-1)\n",
    "#print(conv2_weight.shape)\n",
    "conv2_weight_int = conv2_weight.int()\n",
    "#print(conv2_weight_int)\n",
    "#将第二层的权重导出为txt文件\n",
    "with open('test_array/test_conv2_weight_txt.txt', 'w') as f:\n",
    "    for weight in conv2_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "#将网络第三层的权重导出\n",
    "fc1_weight = net.fc1.weight.data\n",
    "print(fc1_weight)\n",
    "print(fc1_weight.shape)\n",
    "fc1_weight = fc1_weight.view(-1)\n",
    "print(fc1_weight.shape)\n",
    "fc1_weight_int = fc1_weight.int()\n",
    "print(fc1_weight_int)\n",
    "#将第三层的权重导出为txt文件\n",
    "with open('test_array/test_fc1_weight_txt.txt', 'w') as f:\n",
    "    for weight in fc1_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 6, 24, 24])\n",
      "tensor([[[[-11, -11, -11,  ..., -11, -11, -11],\n",
      "          [-11, -11, -11,  ..., -11, -11, -11],\n",
      "          [-11, -11, -11,  ..., -11,  -9, -11],\n",
      "          ...,\n",
      "          [-13, -13,  -7,  ..., -11, -11, -11],\n",
      "          [-15,  -9,  -1,  ..., -11, -11, -11],\n",
      "          [-15,  -9,  -1,  ..., -11, -11, -11]],\n",
      "\n",
      "         [[  7,   7,   7,  ...,   7,   7,   7],\n",
      "          [  7,   7,   7,  ...,   7,   7,   7],\n",
      "          [  7,   7,   7,  ...,   7,   9,   7],\n",
      "          ...,\n",
      "          [  5,   1,  -1,  ...,   7,   7,   7],\n",
      "          [  3,   1,  -7,  ...,   7,   7,   7],\n",
      "          [  3,   1,  -3,  ...,   7,   7,   7]],\n",
      "\n",
      "         [[ -5,  -5,  -5,  ...,  -5,  -5,  -5],\n",
      "          [ -5,  -5,  -5,  ...,  -5,  -5,  -5],\n",
      "          [ -5,  -5,  -5,  ...,  -1,  -3,  -5],\n",
      "          ...,\n",
      "          [ -3,   1,   3,  ...,  -5,  -5,  -5],\n",
      "          [ -1,   1,   9,  ...,  -5,  -5,  -5],\n",
      "          [ -1,   1,  -3,  ...,  -5,  -5,  -5]],\n",
      "\n",
      "         [[ 13,  13,  13,  ...,  13,  13,  13],\n",
      "          [ 13,  13,  13,  ...,  13,  13,  13],\n",
      "          [ 13,  13,  13,  ...,   9,  11,  13],\n",
      "          ...,\n",
      "          [ 15,  11,   5,  ...,  13,  13,  13],\n",
      "          [ 17,   7,   3,  ...,  13,  13,  13],\n",
      "          [ 13,   7,   7,  ...,  13,  13,  13]],\n",
      "\n",
      "         [[ -5,  -5,  -5,  ...,  -5,  -5,  -5],\n",
      "          [ -5,  -5,  -5,  ...,  -5,  -5,  -5],\n",
      "          [ -5,  -5,  -5,  ...,  -1,  -3,  -5],\n",
      "          ...,\n",
      "          [ -3,   1,   3,  ...,  -5,  -5,  -5],\n",
      "          [ -5,   1,   5,  ...,  -5,  -5,  -5],\n",
      "          [ -9, -15, -15,  ...,  -5,  -5,  -5]],\n",
      "\n",
      "         [[ -1,  -1,  -1,  ...,  -1,  -1,  -1],\n",
      "          [ -1,  -1,  -1,  ...,  -1,  -1,  -1],\n",
      "          [ -1,  -1,  -1,  ...,  -1,   1,  -1],\n",
      "          ...,\n",
      "          [ -3,  -7,  -1,  ...,  -1,  -1,  -1],\n",
      "          [ -5,  -7,   1,  ...,  -1,  -1,  -1],\n",
      "          [ -1,   5,   5,  ...,  -1,  -1,  -1]]]], dtype=torch.int32)\n",
      "torch.Size([1, 6, 12, 12])\n",
      "torch.Size([1, 864])\n",
      "tensor([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
      "         -1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,\n",
      "          1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1,\n",
      "         -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
      "          1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,  1,\n",
      "          1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
      "         -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "         -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,\n",
      "          1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "          1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1,\n",
      "         -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1,\n",
      "         -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
      "         -1,  1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "          1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,\n",
      "          1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1]],\n",
      "       dtype=torch.int32)\n",
      "tensor([[  6,   6,  46, 126, -24,  94, -44,  66,  26,  40]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "class watch_scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 3, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()   \n",
    "        self.conv2 = scale_Bconvd(3, 6, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.fc1 = scale_Blinear(6*12*12, 10, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = torch.where(x>127, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.shape)\n",
    "        #print(x.int())\n",
    "        x = self.conv1(x)\n",
    "        x = self.sn1(x)\n",
    "        conv1_out_int = torch.where(x==1., torch.tensor(1.), torch.tensor(0.)).int()\n",
    "        with open('test_array/test_conv1_output_txt.txt', 'w') as f:\n",
    "            for i in range(26):\n",
    "                for j in range(26):\n",
    "                    f.write(format(conv1_out_int[0][0][i][j].item(), 'b') + '\\n')\n",
    "        # print(x.shape)\n",
    "        # print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        print(x.int())\n",
    "        #print(self.conv2.weight)\n",
    "        x = self.pool2(x)\n",
    "        x = self.sn2(x)\n",
    "        print(x.shape)\n",
    "        # print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "        print(x.int())\n",
    "        x_b = torch.where(x==1., torch.tensor(1.), torch.tensor(0.))\n",
    "        x_b_int = x_b.int()\n",
    "        with open('test_array/test_fc1_input_txt.txt', 'w') as f:\n",
    "            for i in range(6*12*12):\n",
    "                f.write(format(x_b_int[0][i].item(), 'b') + '\\n')\n",
    "        #print(self.fc1.weight[0])\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu4(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = watch_scale_leNet()\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "image, label = train_dataset[0]\n",
    "image_b = torch.where(image>0.5, torch.tensor(1.), torch.tensor(0.))\n",
    "image_b_int = image_b.int()\n",
    "with open('test_array/test_image_b_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_b_int[0][i][j].item(), 'b') + '\\n')\n",
    "image = image*255\n",
    "image_int = image.int()\n",
    "with open('test_array/test_image_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_int[0][i][j].item(), '08b') + '\\n')\n",
    "image = image\n",
    "print(image.shape)\n",
    "output = net(image.unsqueeze(0))\n",
    "print(output.int())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,\n",
      "            5.,  3.,  3.,  3.,  3.,  3.,  5.,  3.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,  5.,  3.,  3.,  3.,  3.,  1.,\n",
      "            3.,  1.,  1.,  1.,  1.,  3.,  3.,  3.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  3.,  5.,  3.,  1.,  3.,  1.,  1.,  1.,  1., -1.,\n",
      "           -3., -3., -5., -3., -3., -1., -1.,  3.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  1.,  5.,  1., -1., -3., -5., -5., -5., -5., -5.,\n",
      "           -5., -1., -5., -1., -1.,  1.,  3.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  1., -1., -3., -3., -7., -1., -5., -3., -3., -5.,\n",
      "           -3.,  1., -1.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  3., -1., -1., -3., -5., -1., -3., -3., -1., -3.,\n",
      "           -1.,  1.,  1.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  3.,  1., -3.,  1., -1.,  3.,  1.,  5.,  3.,\n",
      "            1.,  1.,  3.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  1., -1., -3., -1.,  1.,  3.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  3., -1., -3., -1.,  1.,  1.,  5.,\n",
      "            3.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3., -1., -3., -1., -1.,  3.,\n",
      "            3.,  3.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3., -1., -3., -3., -3.,\n",
      "            1.,  3.,  3.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3., -1., -1., -3.,\n",
      "           -3.,  3.,  3.,  3.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,  1., -3.,\n",
      "           -3., -1.,  3.,  1.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,  5.,  1.,\n",
      "            1., -3., -1.,  1.,  3.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,  3.,  3., -1.,\n",
      "           -3., -5., -1.,  1.,  3.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  3.,  5.,  1.,  1., -3., -5.,\n",
      "           -3., -5., -1., -1.,  3.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  5.,  5.,  5.,  3.,  5.,  1.,  3., -1., -3., -3., -5.,\n",
      "           -1., -3.,  1.,  3.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 5.,  5.,  5.,  3.,  5.,  3.,  1.,  3., -1., -3., -5., -3., -3., -3.,\n",
      "            1.,  3.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 3.,  5.,  3.,  1.,  3.,  1., -1., -3., -5., -3., -5., -1., -1.,  3.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 1.,  5.,  1., -1., -3., -5., -5., -3., -5., -1., -3.,  1.,  3.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.],\n",
      "          [ 1.,  1., -3., -3., -3., -3., -3., -1., -3.,  1.,  3.,  5.,  5.,  5.,\n",
      "            5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "weight_conv2 = torch.tensor([[-1.,-1.,-1.],[-1.,1.,-1.],[-1.,1.,-1.]])\n",
    "test_conv2 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "with torch.no_grad():\n",
    "    test_conv2.weight.copy_(weight_conv2)\n",
    "#input来自一个 txt 文件\n",
    "input_data = []\n",
    "with open('/home/ygl/code/BNN_accelerator/train/test_array/test_conv1_output_txt.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        input_data.append(int(line.strip(), 2))\n",
    "input_tensor = torch.tensor(input_data, dtype=torch.float32).view(1, 1, 26, 26)\n",
    "input_tensor = torch.where(input_tensor==1., torch.tensor(1.), torch.tensor(-1.))\n",
    "output = test_conv2(input_tensor)\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

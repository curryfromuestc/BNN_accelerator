{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from BNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_dataset = torchvision.datasets.MNIST(root='/home/curry/code', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='/home/curry/code', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/curry/code/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:42<00:00, 3.97MB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/curry/code/cifar-10-python.tar.gz to /home/curry/code\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#帮我下载cifar10数据集\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='/home/curry/code', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='/home/curry/code', train=False, transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = BinaryConv2d(1, 2, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.conv2 = BinaryConv2d(2, 4, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = BinaryLinear(4*12*12, 10, bias=False)\n",
    "    def forward(self, x):\n",
    "        #大于127的变成1，小于等于127的变成0\n",
    "        x = torch.where(x>0.5, torch.tensor(1.), torch.tensor(-1.))\n",
    "        x = self.conv1(x)\n",
    "        #x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        # x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        x = self.sn1(x)\n",
    "        #print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.relu2(x)\n",
    "        #print(x.int())\n",
    "        x = self.pool2(x) \n",
    "        x = self.sn2(x)\n",
    "        #print(x.shape)\n",
    "        # x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.pool3(x)\n",
    "        #x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.int())\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.465\n",
      "[1,   101] loss: 0.910\n",
      "[1,   201] loss: 0.567\n",
      "[1,   301] loss: 0.368\n",
      "[1,   401] loss: 0.587\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[2,     1] loss: 0.494\n",
      "[2,   101] loss: 0.561\n",
      "[2,   201] loss: 0.466\n",
      "[2,   301] loss: 0.408\n",
      "[2,   401] loss: 0.418\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[3,     1] loss: 0.404\n",
      "[3,   101] loss: 0.422\n",
      "[3,   201] loss: 0.391\n",
      "[3,   301] loss: 0.347\n",
      "[3,   401] loss: 0.338\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[4,     1] loss: 0.476\n",
      "[4,   101] loss: 0.320\n",
      "[4,   201] loss: 0.233\n",
      "[4,   301] loss: 0.288\n",
      "[4,   401] loss: 0.372\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[5,     1] loss: 0.386\n",
      "[5,   101] loss: 0.301\n",
      "[5,   201] loss: 0.324\n",
      "[5,   301] loss: 0.438\n",
      "[5,   401] loss: 0.388\n",
      "Accuracy of the network on the 10000 test images: 90 %\n",
      "[6,     1] loss: 0.267\n",
      "[6,   101] loss: 0.373\n",
      "[6,   201] loss: 0.248\n",
      "[6,   301] loss: 0.322\n",
      "[6,   401] loss: 0.339\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[7,     1] loss: 0.194\n",
      "[7,   101] loss: 0.424\n",
      "[7,   201] loss: 0.242\n",
      "[7,   301] loss: 0.294\n",
      "[7,   401] loss: 0.471\n",
      "Accuracy of the network on the 10000 test images: 87 %\n",
      "[8,     1] loss: 0.330\n",
      "[8,   101] loss: 0.339\n",
      "[8,   201] loss: 0.494\n",
      "[8,   301] loss: 0.367\n",
      "[8,   401] loss: 0.248\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "[9,     1] loss: 0.772\n",
      "[9,   101] loss: 0.344\n",
      "[9,   201] loss: 0.378\n",
      "[9,   301] loss: 0.329\n",
      "[9,   401] loss: 0.419\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[10,     1] loss: 0.549\n",
      "[10,   101] loss: 0.412\n",
      "[10,   201] loss: 0.356\n",
      "[10,   301] loss: 0.185\n",
      "[10,   401] loss: 0.513\n",
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "net = LeNet()\n",
    "from tqdm import tqdm\n",
    "np.int = int\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "LR = 0.001\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "EPOCH = 10\n",
    "device = torch.device('cpu')\n",
    "net.to(device)\n",
    "for epoch in range(EPOCH):\n",
    "    net.train()\n",
    "    for i ,data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        functional.reset_net(net)\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, loss.item()))\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(testloader):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if(100*correct/total>=90):\n",
    "                torch.save(net.state_dict(), 'weight/lenet.pth')\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_Bconvd(BinaryConv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(scale_Bconvd, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
    "    def forward(self, x):\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        scaling_factor = torch.mean(torch.mean(torch.mean(torch.mean(abs(w),dim=3,keepdim=True),dim=2,keepdim=True),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        #print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "    \n",
    "        return F.conv2d(x, bw, self.bias, self.stride,\n",
    "                    self.padding, self.dilation, self.groups)\n",
    "class scale_Blinear(BinaryLinear):\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super(scale_Blinear, self).__init__(in_features, out_features, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        w = self.weight\n",
    "        bw = BinaryWeight.apply(w)\n",
    "        # print(w.shape)\n",
    "        scaling_factor = torch.mean(torch.mean(abs(w),dim=1,keepdim=True),dim=0,keepdim=True)\n",
    "        scaling_factor = scaling_factor.detach()\n",
    "        #print(scaling_factor)\n",
    "        # bw = scaling_factor * BinaryWeight.apply(w)\n",
    "        \n",
    "        return F.linear(x, bw, self.bias)\n",
    "    \n",
    "class scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 2, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()\n",
    "        self.conv2 = scale_Bconvd(2, 4, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.fc1 = scale_Blinear(4*12*12, 10, bias=False)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.fc2 = scale_Blinear(120, 84, bias=False)\n",
    "        # self.relu4 = nn.ReLU()\n",
    "        # self.fc3 = scale_Blinear(84, num_classes, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = torch.where(x>0.5, torch.tensor(1.), torch.tensor(-1.))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool1(x)\n",
    "        #print(x.int())\n",
    "        x = self.sn1(x)\n",
    "        #print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        #print(x.int())\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.relu2(x)\n",
    "        #print(x.int())\n",
    "        x = self.pool2(x)\n",
    "        x = self.sn2(x)\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.pool3(x)\n",
    "        #x = torch.where(x>0, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.int())\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 90 %\n"
     ]
    }
   ],
   "source": [
    "#将权重加载，二值化，保存为另外一个pth文件\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "net = LeNet()\n",
    "device = torch.device('cpu')\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load('weight/lenet.pth',weights_only=True, map_location=device))\n",
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        param.data = BinaryWeight.apply(param.data)\n",
    "torch.save(net.state_dict(), 'weight/lenet_binary.pth')\n",
    "#加载二值化后的权重\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.,  1.,  ..., -1., -1., -1.],\n",
      "        [ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
      "        [ 1., -1., -1.,  ...,  1.,  1.,  1.],\n",
      "        ...,\n",
      "        [ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  ...,  1.,  1.,  1.]])\n",
      "torch.Size([10, 576])\n",
      "torch.Size([5760])\n",
      "tensor([ 1, -1,  1,  ...,  1,  1,  1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#将网络第一层的权重导出\n",
    "conv1_weight = net.conv1.weight.data\n",
    "#print(conv1_weight)\n",
    "conv1_weight = conv1_weight.view(-1)\n",
    "#print(conv1_weight.shape)\n",
    "conv1_weight_int = conv1_weight.int()\n",
    "#print(conv1_weight_int)\n",
    "#将第一层的权重导出为txt文件\n",
    "with open('test_array/test_conv1_weight_txt.txt', 'w') as f:\n",
    "    for weight in conv1_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "#将网络第二层的权重导出\n",
    "conv2_weight = net.conv2.weight.data\n",
    "#print(conv2_weight.shape)\n",
    "#print(conv2_weight)\n",
    "conv2_weight = conv2_weight.view(-1)\n",
    "#print(conv2_weight.shape)\n",
    "conv2_weight_int = conv2_weight.int()\n",
    "#print(conv2_weight_int)\n",
    "#将第二层的权重导出为txt文件\n",
    "with open('test_array/test_conv2_weight_txt.txt', 'w') as f:\n",
    "    for weight in conv2_weight_int:\n",
    "        weight = weight.item()\n",
    "        if weight < 0:\n",
    "            weight = 0\n",
    "        f.write(format(weight, 'b') + '\\n')\n",
    "#将网络第三层的权重导出\n",
    "fc1_weight = net.fc1.weight.data\n",
    "print(fc1_weight)\n",
    "print(fc1_weight.shape)\n",
    "fc1_weight = fc1_weight.view(-1)\n",
    "print(fc1_weight.shape)\n",
    "fc1_weight_int = fc1_weight.int()\n",
    "print(fc1_weight_int)\n",
    "#将第三层的权重导出为txt文件\n",
    "for i in range(10):\n",
    "    with open('test_array/test_fc1_weight_txt'+str(i)+'.txt', 'w') as f:\n",
    "        for weight in fc1_weight_int[i*576:i*576+576]:\n",
    "            weight = weight.item()\n",
    "            if weight < 0:\n",
    "                weight = 0\n",
    "            f.write(format(weight, 'b') + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor([[[[ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  3,  1,\n",
      "            1,  1,  1, -1,  1,  3,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  3,  1, -1, -1, -1, -1, -3, -5,\n",
      "           -5, -5, -5, -7, -3,  1,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  3,  1, -1, -3, -5, -7, -7, -7, -7, -5, -5,\n",
      "           -3,  3, -1,  1,  1,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  1, -3, -7, -5, -7, -5, -5, -5, -5, -5, -1,\n",
      "            3,  7,  7,  7,  5,  7,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5, -1, -1, -3, -3, -5, -3, -1,  1, -1, -1,\n",
      "            3,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  7,  3,  5,  1, -1, -3,  1,  5,  7,  5,  3,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  7,  3,  5, -3, -3, -1,  5,  5,  7,  3,\n",
      "            7,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5, -1, -5, -1,  1,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  7,  3,  1, -3, -1,  1,  3,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  7,  3, -1, -3, -5, -1,  3,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  7,  3,  1, -5, -3, -3,\n",
      "            1,  3,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  7,  3,  3, -3, -3,\n",
      "           -5, -1,  3,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  7,  5,  3, -1,\n",
      "           -7, -1,  1,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  3,  1, -1, -5,\n",
      "           -5, -3,  3,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  3,  1, -3, -5, -5, -7,\n",
      "           -5, -3,  3,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  3, -1, -5, -5, -7, -5, -3,\n",
      "           -1,  1,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  3,  1, -3, -3, -7, -5, -3, -1,  3,\n",
      "            5,  5,  7,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  3,  1, -1, -3, -5, -5, -7, -3, -1,  3,  5,  5,\n",
      "            7,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  3,  1, -3, -5, -7, -5, -7, -5, -3,  1,  5,  5,  7,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  3, -1, -5, -5, -7, -5, -5, -3, -1,  3,  3,  7,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  3,  3, -1,  1,  1,  1,  1,  3,  5,  5,  7,  5,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  7,  5,  7,  7,  7,  7,  7,  5,  7,  5,  5,  5,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "          [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "            5,  5,  5,  5,  5,  5,  5,  5,  5]],\n",
      "\n",
      "         [[-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -5, -7,\n",
      "           -7, -7, -7, -9, -7, -5, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -5, -7, -9, -9, -9, -9, -7, -5,\n",
      "           -5, -5, -5, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -5, -7, -9, -7, -5, -3, -3, -3, -3, -1,  3,\n",
      "            5,  7,  7,  9,  5,  1, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -1,  1,  3,  3,  3,  3,  3,  3,\n",
      "            3,  3,  3,  3,  1, -1, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3,  1,  3,  7,  5,  5,  3,  5,  7,  9,  7,  3,\n",
      "           -1, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -1,  3,  5,  5,  3,  5,  5,  5,  3,  5,  3,\n",
      "            1, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -1, -1,  1,  1,  1, -1, -3, -3, -1, -1,\n",
      "           -1, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3,  1,  3,  3, -1, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -1,  3,  5,  1, -5, -7, -5, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -1,  3,  3,  1, -5, -5, -5,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -1,  3,  5,  3, -3, -7,\n",
      "           -7, -5, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -1,  3,  7,  5,  1,\n",
      "           -5, -5, -5, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -1,  1,  3,  3,\n",
      "            1, -1, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -5, -7, -5, -1,\n",
      "            3,  1, -1, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -5, -7, -7, -5, -1,  1,\n",
      "            3,  1, -1, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -5, -5, -5, -1,  1,  3,  5,\n",
      "            7,  5,  1, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -5, -7, -7, -3,  1,  3,  5,  7,  7,\n",
      "            5,  1, -1, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -5, -7, -9, -7, -5, -1,  1,  5,  7,  7,  5,  1,\n",
      "           -1, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -5, -7, -7, -5, -3, -1,  1,  3,  5,  5,  5,  1, -1, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -5, -5, -5, -1,  1,  3,  3,  5,  7,  7,  3, -1, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -1,  3,  7,  9,  9,  9,  9,  7,  5,  1, -1, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -1,  1,  3,  3,  3,  3,  3,  1, -1, -3, -3, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3],\n",
      "          [-3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3, -3,\n",
      "           -3, -3, -3, -3, -3, -3, -3, -3, -3]]]], dtype=torch.int32)\n",
      "torch.Size([1, 4, 24, 24])\n",
      "tensor([[[[ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,\n",
      "            -4,  -4,  -4,  -4,  -6,  -2,  -6,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -4,  -6,  -6,  -6,\n",
      "            -6,  -6,  -6,  -6,  -4,  -4,  -2,  -6,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -6,  -4,  -6,  -4,  -2,   0,   0,   0,\n",
      "             2,   4,   8,   4,   8,   8,   8,   2,  -2,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -6,  -2,  -2,   2,   2,   6,   8,   8,   8,\n",
      "            10,  14,   8,  10,   8,   8,   6,   0,  -6,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -2,   0,   4,   6,  10,  12,  10,  10,  12,   8,\n",
      "            10,   4,  -2,  -8,  -6,  -6, -10, -10,  -6,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -2,   2,   6,  12,   8,   8,   6,   4,   4,   4,\n",
      "             4,   4,  -4,  -8, -10, -10,  -8,  -6,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -6,  -8,  -6,  -4,  -2,   4,   0,  -2,  -6,  -8,\n",
      "            -8,  -2,  -4,  -6,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -6,  -8,  -6,  -4,   2,   2,  -4, -10, -10,\n",
      "           -10, -10,  -8,  -6,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -2,   0,   4,   4,   2,  -6,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -8,  -4,   0,   8,   2,  -2,\n",
      "            -4,  -6,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -6,  -4,   2,   8,   6,\n",
      "             0,  -2,  -6,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -8,  -4,   2,   4,\n",
      "            10,   4,  -2,  -4,  -6,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -6,  -6,   0,\n",
      "             6,  12,   4,   2,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -6, -10,\n",
      "            -6,   0,   4,   6,   0,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -6,  -8,\n",
      "            -8,   0,   8,   6,  -2,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -4,  -4,   0,   2,\n",
      "             8,  10,   8,   4,   0,  -2,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -2,   0,   2,   8,  12,\n",
      "            10,   6,   4,   4,  -2,  -6,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -6,  -4,  -6,  -4,  -2,   6,  12,  10,   6,\n",
      "             4,   0,  -2,  -8, -10,  -6,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -6,  -4,  -4,  -2,   2,   2,   8,  12,   6,   4,   0,\n",
      "            -2,  -8, -12,  -8,  -6,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -6,  -4,  -4,   0,   2,   6,  10,  12,  10,   4,   0,  -2,  -8,\n",
      "           -12,  -8,  -6,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,   0,   2,   8,   8,  14,  12,  10,   8,   4,   2,  -6, -12,  -8,\n",
      "            -6,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -2,   6,   8,   6,   2,   0,   0,  -2,  -2,  -8, -10,  -6,  -4,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -6,  -6,  -6,  -8,  -8,  -8, -10, -12,  -8,  -6,  -4,  -4,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4]],\n",
      "\n",
      "         [[ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,\n",
      "            -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,\n",
      "            -2,  -2,  -2,  -2,  -4,  -4,  -4,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -4,  -6,  -8,  -8,  -8,\n",
      "            -8,  -8,  -8,  -8, -10, -10,  -4,  -4,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -4,  -6,  -8, -10, -12, -10, -10, -10,\n",
      "           -12, -10,  -6,  -6,  -6,  -2,   2,   4,   0,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -4,  -8, -12, -12, -12,  -8,  -6,  -6,  -6,\n",
      "            -4,  -4,   2,   4,   2,   6,   8,   2,   0,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -4,  -6, -10,  -8,  -4,  -6,  -4,  -4,  -2,  -2,\n",
      "             0,   6,  12,   6,   8,   8,   4,   4,   0,  -2],\n",
      "          [ -2,  -2,  -2,  -2,   0,  -8,  -4,   2,   2,   2,   4,   6,  10,  10,\n",
      "             6,  10,  14,   6,   4,   4,   2,   0,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,   0,   2,   4,   6,   4,   2,   6,   8,   8,   6,\n",
      "             6,   8,   2,   0,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,   0,   2,   4,  -2,   0,   4,   6,   4,   4,\n",
      "             4,   4,   2,   0,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,   2,  -4,   2,   2,   6,   0,  -4,\n",
      "            -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,   0,   2,   2,   2,  -2,   0,  -4,\n",
      "            -6,  -4,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,   0,   4,  -2,   0,   2,   0,\n",
      "            -6,  -4,  -4,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,   0,   2,   2,   4,  -2,\n",
      "             0,  -2,  -4,  -6,  -4,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,   0,   4,   0,   2,\n",
      "             0,  -2,  -2,  -4,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,   0,   4,   0,\n",
      "             0,  -6,  -6,   4,   2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -4,  -4,  -6,\n",
      "           -10,  -2,  -2,   4,   4,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -4,  -6, -10, -14, -12,\n",
      "            -6,  -4,   2,   6,  10,   0,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -4,  -8, -14, -12,  -6,  -6,\n",
      "             0,   4,  10,  14,   4,   0,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -2,  -2,  -4,  -6,  -8, -10, -16,  -8,  -6,   0,   4,\n",
      "            10,  14,  12,   6,   4,   0,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -2,  -2,  -4,  -6, -10, -12, -12, -12,  -6,  -2,   4,  10,  14,\n",
      "            12,   6,   6,   2,   0,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -4,  -6, -10, -14, -12,  -8,  -4,  -6,   0,   6,  14,  12,   6,\n",
      "             6,   2,   0,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -6,  -8,  -6,  -2,   0,   2,   4,   6,  10,  16,   8,   6,   2,\n",
      "             0,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,  -4,  -4,   2,   8,   8,  10,  10,  12,  12,   6,   4,   0,  -2,\n",
      "            -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2],\n",
      "          [ -2,   2,   0,   8,   8,   6,   6,   6,   4,   6,   2,   0,  -2,  -2,\n",
      "            -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2,  -2]],\n",
      "\n",
      "         [[ 14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,\n",
      "            14,  14,  14,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,\n",
      "            14,  14,  14,  14,  12,  16,  12,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  12,  14,  12,  12,  12,\n",
      "            12,  12,  12,  12,  10,  10,  12,  12,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  12,  14,  12,  10,   8,   6,   6,   6,\n",
      "             4,   2,   2,  -2,   2,  -2,   2,   8,  12,  14],\n",
      "          [ 14,  14,  14,  14,  14,  12,  12,   8,   4,   0,  -4,  -6,  -6,  -6,\n",
      "            -8,  -8, -10,  -8,  -6,  -6,   0,   6,  12,  14],\n",
      "          [ 14,  14,  14,  14,  12,   6,   2,  -4,  -8, -10, -12, -12, -10, -14,\n",
      "            -8,  -6,  -4,   2,   4,   4,   8,   8,  12,  14],\n",
      "          [ 14,  14,  14,  14,  12,   4,  -4, -10, -10, -10, -12, -14, -10, -10,\n",
      "           -10,  -6,   2,  10,  12,  12,  10,  12,  14,  14],\n",
      "          [ 14,  14,  14,  14,  16,  10,   4,  -2,  -8, -10, -10,  -4,   0,   2,\n",
      "             2,   0,   6,  12,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  16,  14,   8,  -2,  -8,  -8,   2,   8,  12,\n",
      "            12,  12,  10,  12,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,   4,  -6, -14,  -2,   8,  12,\n",
      "            14,  14,  14,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  16,  10,   2, -10,  -6,   0,   8,\n",
      "            14,  12,  14,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  16,  12,   2,  -8, -10,   0,\n",
      "             6,  12,  12,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  16,  10,   2,  -8, -10,\n",
      "            -4,   2,   8,  14,  12,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  16,  12,   4,  -6,\n",
      "           -12,  -6,  -2,   8,  10,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  16,  12,   4,\n",
      "             0, -10, -10,   0,   6,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  12,  16,  10,\n",
      "             2,  -6, -14,  -4,   4,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  14,  12,  14,  10,   6,   0,\n",
      "            -6,  -8, -10, -10,   2,  12,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  14,  14,  14,  12,  12,   6,   0,  -6, -10,\n",
      "            -8, -12, -10,  -6,   4,  12,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  14,  14,  12,  14,  12,  10,   4,  -4, -10,  -8, -12,\n",
      "           -10,  -6,   0,   6,   8,  12,  14,  14,  14,  14],\n",
      "          [ 14,  14,  14,  12,  14,  10,   8,   4,   0,  -6,  -6, -12, -10,  -6,\n",
      "             0,   6,  10,  10,  12,  14,  14,  14,  14,  14],\n",
      "          [ 14,  12,  14,  10,   6,   0,  -4,  -8, -10,  -8, -10,  -6,   0,   6,\n",
      "            10,  10,  12,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  10,   4,   2,  -6,  -8, -10,  -8, -10, -10,  -4,   4,  10,  10,\n",
      "            12,  14,  14,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,   8,   0,  -6,  -4,  -4,  -6,  -6,  -4,   0,   6,   8,  12,  14,\n",
      "            14,  14,  14,  14,  14,  14,  14,  14,  14,  14],\n",
      "          [ 14,  14,   8,   4,   4,   6,   6,   6,   8,  10,  10,  12,  14,  14,\n",
      "            14,  14,  14,  14,  14,  14,  14,  14,  14,  14]],\n",
      "\n",
      "         [[ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,\n",
      "            -4,  -4,  -4,  -4,  -2,  -6,  -6,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -2,  -4,  -6,  -6,  -6,\n",
      "            -6,  -6,  -6,  -6,  -8,  -4, -10,  -6,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -2,  -4,  -6,  -8,  -6,  -8,  -8,  -8,\n",
      "           -10,  -8,  -8,  -4,  -4,  -8,   0,  -2,  -2,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -2,  -6,  -6, -10,  -6,  -6,  -4,  -4,  -4,\n",
      "            -2,  -2,   4,   2,   8,   4,   6,   4,  -2,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -6,  -4,   0,  -6,  -2,   0,   2,   2,   0,   4,\n",
      "             2,   4,   2,   8,   2,   6,   2,   2,  -2,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -2,  -2,   2,   4,   4,   4,   2,   4,   8,   4,\n",
      "             8,   4,   4,   0,  -2,  -2,   0,  -2,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -6,   0,   2,   4,   6,   8,   8,   2,   2,   8,\n",
      "             4,   6,   4,  -2,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -6,  -4,  -2,   4,   6,   2,   0,  -6,  -2,\n",
      "            -2,  -2,   0,  -2,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -2,   4,   8,   4,  -6,  -6,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,   0,   0,   8,   4,   2,  -6,\n",
      "            -8,  -6,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -2,   0,   6,   4,   2,\n",
      "            -4, -10,  -6,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,   0,   0,   6,   8,\n",
      "            -2,   0,  -6,  -8,  -6,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -2,   2,   4,\n",
      "            10,   0,   0,  -6,  -8,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -6,  -2,   6,\n",
      "             2,   4,   0,  -2,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -2,  -6,  -8,\n",
      "            -4,  -4,   4,   2,  -2,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -2,  -4,  -8,  -8,  -6,\n",
      "            -4,  -2,   0,   4,   4,  -2,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -2,  -6,  -8,  -6,  -4,   0,\n",
      "            -2,   2,   8,   8,   6,  -2,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -4,  -4,  -2,  -4,  -6,  -8,  -6,  -6,   0,  -2,   2,\n",
      "             8,   8,   6,   4,   2,  -2,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,  -4,  -2,  -4,  -8,  -6, -10,  -6,  -4,  -4,   2,   8,   8,\n",
      "             6,   4,   0,   0,  -2,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -2,  -4,  -8,  -8,  -6,  -6,  -2,   0,  -2,   4,   8,   6,   4,\n",
      "             0,   0,  -2,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -8,  -2,  -4,  -4,   2,   4,   2,   4,   8,   6,   6,   0,   0,\n",
      "            -2,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -2,  -2,   8,   2,   6,   8,   8,  10,   6,   4,   2,  -2,  -4,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4],\n",
      "          [ -4,  -4,   2,   2,   6,   4,   4,   4,   2,   0,   0,  -2,  -4,  -4,\n",
      "            -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4,  -4]]]],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([1, 4, 12, 12])\n",
      "torch.Size([1, 576])\n",
      "tensor([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "          1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
      "         -1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,\n",
      "          1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1,\n",
      "         -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,\n",
      "         -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,  1,\n",
      "          1,  1,  1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
      "          1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1,\n",
      "         -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
      "          1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
      "         -1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1, -1, -1, -1,  1,  1,\n",
      "         -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1, -1, -1,\n",
      "         -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "          1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1, -1, -1,\n",
      "         -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
      "          1,  1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1]],\n",
      "       dtype=torch.int32)\n",
      "tensor([[ 12,   4,  34,  86, -34,  68, -10,  22,  20,   8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=10_000)  # 设置阈值为一个足够大的数，显示完整张量\n",
    "class watch_scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 2, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()   \n",
    "        self.conv2 = scale_Bconvd(2, 4, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.fc1 = scale_Blinear(4*12*12, 10, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = torch.where(x>127, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.shape)\n",
    "        #print(x.int())\n",
    "        x = self.conv1(x)\n",
    "        print(x.int())\n",
    "        x = self.sn1(x)\n",
    "        conv1_out_int = torch.where(x==1., torch.tensor(1.), torch.tensor(0.)).int()\n",
    "        with open('test_array/test_conv1_output_txt.txt', 'w') as f:\n",
    "            for i in range(26):\n",
    "                for j in range(26):\n",
    "                    f.write(format(conv1_out_int[0][0][i][j].item(), 'b') + '\\n')\n",
    "        # print(x.shape)\n",
    "        # print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        print(x.int())\n",
    "        #print(self.conv2.weight)\n",
    "        x_b = torch.where(x==1., torch.tensor(1.), torch.tensor(0.))\n",
    "        x_b_int = x_b.int()\n",
    "        # with open('test_array/test_maxpool_input_txt.txt', 'w') as f:\n",
    "        #     for i in range(4*12*12):\n",
    "        #         f.write(format(x_b_int[0][i].item(), 'b') + '\\n')\n",
    "        x = self.pool2(x)\n",
    "        x = self.sn2(x)\n",
    "        print(x.shape)\n",
    "        # print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "        print(x.int())\n",
    "        x_b = torch.where(x==1., torch.tensor(1.), torch.tensor(0.))\n",
    "        x_b_int = x_b.int()\n",
    "        with open('test_array/test_fc1_input_txt.txt', 'w') as f:\n",
    "            for i in range(4*12*12):\n",
    "                f.write(format(x_b_int[0][i].item(), 'b') + '\\n')\n",
    "        #print(self.fc1.weight[0])\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu4(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = watch_scale_leNet()\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "image, label = train_dataset[0]\n",
    "image_b = torch.where(image>0.5, torch.tensor(1.), torch.tensor(0.))\n",
    "image_b_int = image_b.int()\n",
    "with open('test_array/test_image_b_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_b_int[0][i][j].item(), 'b') + '\\n')\n",
    "image = image*255\n",
    "image_int = image.int()\n",
    "with open('test_array/test_image_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_int[0][i][j].item(), '08b') + '\\n')\n",
    "image = image\n",
    "print(image.shape)\n",
    "output = net(image.unsqueeze(0))\n",
    "print(output.int())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=10_000)  # 设置阈值为一个足够大的数，显示完整张量\n",
    "class watch_scale_leNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, T=4):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = scale_Bconvd(1, 2, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.sn1 = BinaryActivation()   \n",
    "        self.conv2 = scale_Bconvd(2, 4, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.sn2 = BinaryActivation()\n",
    "        self.fc1 = scale_Blinear(4*12*12, 10, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = torch.where(x>127, torch.tensor(1.), torch.tensor(-1.))\n",
    "        #print(x.shape)\n",
    "        #print(x.int())\n",
    "        x = self.conv1(x)\n",
    "        print(x.int())\n",
    "        x = self.sn1(x)\n",
    "        conv1_out_int = torch.where(x==1., torch.tensor(1.), torch.tensor(0.)).int()\n",
    "        with open('test_array/test_conv1_output_txt.txt', 'w') as f:\n",
    "            for i in range(26):\n",
    "                for j in range(26):\n",
    "                    f.write(format(conv1_out_int[0][0][i][j].item(), 'b') + '\\n')\n",
    "        # print(x.shape)\n",
    "        # print(x.int())\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        print(x.int())\n",
    "        #print(self.conv2.weight)\n",
    "        x_b = torch.where(x==1., torch.tensor(1.), torch.tensor(0.))\n",
    "        x_b_int = x_b.int()\n",
    "        with open('test_array/test_maxpool_input_txt.txt', 'w') as f:\n",
    "            for i in range(4*12*12):\n",
    "                f.write(format(x_b_int[0][i].item(), 'b') + '\\n')\n",
    "        x = self.pool2(x)\n",
    "        x = self.sn2(x)\n",
    "        print(x.shape)\n",
    "        # print(x.int())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "        print(x.int())\n",
    "        x_b = torch.where(x==1., torch.tensor(1.), torch.tensor(0.))\n",
    "        x_b_int = x_b.int()\n",
    "        with open('test_array/test_fc1_input_txt.txt', 'w') as f:\n",
    "            for i in range(4*12*12):\n",
    "                f.write(format(x_b_int[0][i].item(), 'b') + '\\n')\n",
    "        #print(self.fc1.weight[0])\n",
    "        x = self.fc1(x)\n",
    "        # x = self.relu3(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu4(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = watch_scale_leNet()\n",
    "net.load_state_dict(torch.load('weight/lenet_binary.pth',weights_only=True))\n",
    "image, label = train_dataset[0]\n",
    "image_b = torch.where(image>0.5, torch.tensor(1.), torch.tensor(0.))\n",
    "image_b_int = image_b.int()\n",
    "with open('test_array/test_image_b_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_b_int[0][i][j].item(), 'b') + '\\n')\n",
    "image = image*255\n",
    "image_int = image.int()\n",
    "with open('test_array/test_image_txt.txt', 'w') as f:\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            f.write(format(image_int[0][i][j].item(), '08b') + '\\n')\n",
    "image = image\n",
    "print(image.shape)\n",
    "output = net(image.unsqueeze(0))\n",
    "print(output.int())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
